{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "seq_csv = pd.read_csv(\"/data/tmp/watch_sequences/10427024113477157/xumi_feat_10427024113477157\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "import os\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from goatools.go_enrichment import GOEnrichmentStudy\n",
    "from goatools import obo_parser\n",
    "\n",
    "import wget\n",
    "\n",
    "DATA_DIR = \"/data/dd-analysis\"\n",
    "\n",
    "#LOAD DATABASE ANNOTATIONS\n",
    "refseq_genes = pd.read_csv(\"/data/genomes/annotations/refseq_genes_export.csv\", delimiter=\"\\t\")\n",
    "entrez = pd.read_csv(\"/data/genomes/annotations/Homo_sapiens.GRCh38.95.entrez.tsv\",delimiter = \"\\t\")\n",
    "refseq_xref = pd.read_csv(\"/data/genomes/annotations/Homo_sapiens.GRCh38.95.refseq.tsv\",delimiter = \"\\t\")\n",
    "\n",
    "\n",
    "#LOAD GENE ONTOLOGIES FOR HG38\n",
    "from Bio.UniProt import GOA\n",
    "fopen = open(\"/data/genomes/annotations/goa_human.gaf\")\n",
    "itr = GOA.gafiterator(fopen)\n",
    "records = list(itr)\n",
    "ontologies = pd.DataFrame.from_dict(records)    \n",
    "\n",
    "def init_go_terms(tmpfolder, dataset):\n",
    "    dsname = dataset[\"dataset\"]\n",
    "    \n",
    "    #READ TRANSCRIPT ALIGNMENTS\n",
    "    samfile = pysam.AlignmentFile(\"/data/dd-analysis/datasets/{}/tophat/accepted_hits.bam\".format(dsname), \"rb\")\n",
    "    all_alignments = [a for a in  samfile]\n",
    "    names =[e.reference_name for e in all_alignments]\n",
    "    query_names = [e.query_name for e in all_alignments]\n",
    "    \n",
    "    #LOAD TRANSCRIPTOME FASTA FILE\n",
    "    #this is the file that the reads above were aligned to and contains add'l annotations\n",
    "    with open(\"/data/transcriptomes/Homo_sapiens.GRCh38.cdna.all.fa\") as f:\n",
    "        farecords = SeqIO.parse(f, \"fasta\")\n",
    "        recs = [r for r in farecords]\n",
    "    for r in recs:\n",
    "        r.id = r.id[:r.id.index(\".\")]\n",
    "    \n",
    "\n",
    "        \n",
    "    gsre = re.compile(\"gene_symbol:(\\S+)\")\n",
    "    dre = re.compile(\"description:(.*)\")\n",
    "    chromre = re.compile(\"chromosome:(\\S+)\")\n",
    "    genere = re.compile(\"gene:(\\S+)\")\n",
    "\n",
    "    transcript_gene_symbols = dict([(r.id, gsre.search(r.description).groups()[0]) for r in recs if \"gene_symbol:\" in r.description])\n",
    "    transcript_descriptions = dict([(r.id, dre.search(r.description).groups()[0]) for r in recs if \"description:\" in r.description])\n",
    "    transcript_chromosome = dict([(r.id, chromre.search(r.description).groups()[0]) for r in recs if \"chromosome:\" in r.description])\n",
    "    transcript_geneid_withversion = dict([(r.id, genere.search(r.description).groups()[0]) for r in recs if \"description:\" in r.description])\n",
    "    transcript_geneid = dict([(k,v[:v.index(\".\")]) for k, v in transcript_geneid_withversion.items()])\n",
    "    entrez_by_gene = entrez.drop_duplicates(\"gene_stable_id\").set_index(entrez.drop_duplicates(\"gene_stable_id\").gene_stable_id)\n",
    "    mapped_genes = set(g for g in transcript_geneid.values() if entrez_by_gene.index.contains(g))\n",
    "    transcript_xref = dict([(k ,entrez_by_gene.loc[g].xref if g in mapped_genes else None) for k,g in transcript_geneid.items() ])\n",
    "\n",
    "    \n",
    "    #many-to-one mapping between UMI_IDS and transcripts\n",
    "    umi2tx = pd.DataFrame.from_dict([{\"umi_id\":qn,\"dataset\":qn.split(\"_\")[0],\"umi\":qn.split(\"_\")[1],\"transcript\":names[i][:names[i].index(\".\")]} \n",
    "                                    for i,qn in enumerate(query_names)])\n",
    "    \n",
    "    #mappping from transcript gene symbols (recorded in the ensembl cdna file to \n",
    "    #refseq genes\n",
    "    \n",
    "    refseq_symbol_names_jointable = pd.concat([refseq_genes.name2,refseq_genes.name],axis = 1)\n",
    "    refseq_symbols_idx = pd.Index(refseq_genes.name2.drop_duplicates().str.upper())\n",
    "    refseq_symbol_ids = pd.Series(refseq_genes.name2.drop_duplicates().index, index=refseq_symbols_idx)\n",
    "    \n",
    "    tx_symbols = pd.Series(transcript_gene_symbols)\n",
    "    refseq_matches = tx_symbols.apply(lambda x: refseq_symbol_ids[x] if x in refseq_symbols_idx else None).dropna()\n",
    "    #roughly 85% of transcripts can be matched refseq IDs\n",
    "    transcript_refseqs = refseq_matches.apply(lambda x: refseq_genes.name.loc[x])\n",
    "\n",
    "    TX_INFO = pd.concat([pd.Series(transcript_descriptions).rename(\"desc\"),\n",
    "                     pd.Series(transcript_gene_symbols).rename(\"symbol\"),\n",
    "                    pd.Series(transcript_geneid).rename(\"ensembl_gene\"),\n",
    "                     pd.Series(transcript_xref).rename(\"ncbi_gene\")\n",
    "                    ],axis = 1, sort=True)\n",
    "    \n",
    "    all_umis = umi2tx.umi_id.unique()\n",
    "    \n",
    "    \n",
    "    #GOTTA REMEMBER TO FILTER OUT ALL SHITTY UMIS!\n",
    "    nosegfeat_fn = f\"/data/tmp/watch_sequences/{dsname}/xumi_feat_{dsname}\"\n",
    "    nosegfeat_df = pd.read_csv(nosegfeat_fn,names=[\"umi\",\"check\",\"blank1\",\"blank2\",\"sequence\"])\n",
    "    nosegfeat_df.iloc[:,1].unique()\n",
    "    good_umis_idx = nosegfeat_df.loc[nosegfeat_df.iloc[:,1]==0].index\n",
    "    \n",
    "    segfn = f\"/data/tmp/watch_sequences/{dsname}/xumi_segment_base_{dsname}\"\n",
    "    segdf = pd.read_csv(segfn,names=[\"umi\",\"seg\",\"1\",\"2\",\"3\"]).loc[good_umis_idx]\n",
    "\n",
    "    go_obo_url = 'http://purl.obolibrary.org/obo/go/go-basic.obo'\n",
    "    data_folder = '/data/go'\n",
    "\n",
    "    # Check if we have the ./data directory already\n",
    "    if(not os.path.isfile(data_folder)):\n",
    "        # Emulate mkdir -p (no error if folder exists)\n",
    "        try:\n",
    "            os.mkdir(data_folder)\n",
    "        except OSError as e:\n",
    "            if(e.errno != 17):\n",
    "                raise e\n",
    "    else:\n",
    "        raise Exception('Data path (' + data_folder + ') exists as a file. '\n",
    "                       'Please rename, remove or change the desired location of the data path.')\n",
    "    \n",
    "    # Check if the file exists already\n",
    "    if(not os.path.isfile(data_folder+'/go-basic.obo')):\n",
    "        go_obo = wget.download(go_obo_url, data_folder+'/go-basic.obo')\n",
    "    else:\n",
    "        go_obo = data_folder+'/go-basic.obo'\n",
    "\n",
    "    # Import the OBO parser from GOATools\n",
    "    go = obo_parser.GODag(go_obo)\n",
    "\n",
    "\n",
    "    a0 = ontologies.sort_values(\"DB_Object_Symbol\")\n",
    "    \n",
    "    #for each cell in the selected segmentation, list all transcripts (with counts)\n",
    "    #that appear\n",
    "    \n",
    "\n",
    "\n",
    "    umi2txall = umi2tx.join( TX_INFO,on = \"transcript\")\n",
    "    ontologies_by_symbol = ontologies.set_index(ontologies.DB_Object_Symbol)\n",
    "    ontologies_by_symbol[\"GO_NAME\"] = ontologies_by_symbol.GO_ID.apply(lambda x: go[x].name).rename(\"GO_NAME\")\n",
    "    umi2go=umi2txall.drop_duplicates([\"umi\",\"symbol\"]).join(ontologies_by_symbol, on=\"symbol\" )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpfolder = \"/data/tmp/watch_sequences/10427024113477157\"\n",
    "dataset = {'allfiles': {'annotations': 'all_v2/website_datasets/bh0085_gmail_com/annotations_10427024113477157.json.gz', 'coords': 'all_v2/website_datasets/bh0085_gmail_com/coords_10427024113477157.json.gz', 'xumi_base': '/website_datasets/bh0085_gmail_com/xumi_base_10427024113477157', 'xumi_feat': '/website_datasets/bh0085_gmail_com/xumi_feat_10427024113477157', 'xumi_segment_base': '/website_datasets/bh0085_gmail_com/xumi_segment_base_10427024113477157', 'xumi_segment_feat': '/website_datasets/bh0085_gmail_com/xumi_segment_feat_10427024113477157'}, 'annotations_url': 'https://storage.googleapis.com/slides.dna-microscopy.org/all_v2/website_datasets/bh0085_gmail_com/annotations_10427024113477157.json.gz', 'dataset': '10427024113477157', 'display_name': 'WT001', 'downloadUrl': 'https://storage.googleapis.com/slides.dna-microscopy.org/all_v2/website_datasets/bh0085_gmail_com/coords_10427024113477157.json.gz', 'email': 'bh0085@gmail.com', 'filename': 'all_v2/website_datasets/bh0085_gmail_com/coords_10427024113477157.json.gz', 'server_job_progresses': {'INIT_BLAT': 0, 'INIT_COLOR_BUFFERS': 0, 'INIT_DATABASE_FILES': 0, 'INIT_DATASET_DATABASE': 0, 'INIT_FRONTEND': 0, 'INIT_GO_TERMS': 0, 'INIT_TOPHAT_TRANSCRIPTS': 0, 'INIT_XY_BUFFERS': 0}, 'server_job_statuses': {'INIT_BLAT': 'COMPLETE', 'INIT_COLOR_BUFFERS': 'WAITING', 'INIT_DATABASE_FILES': 'WAITING', 'INIT_DATASET_DATABASE': 'WAITING', 'INIT_FRONTEND': 'COMPLETE', 'INIT_GO_TERMS': 'FAILED', 'INIT_TOPHAT_TRANSCRIPTS': 'COMPLETE', 'INIT_XY_BUFFERS': 'WAITING'}, 'server_process_progress': 0, 'server_process_status': 'RUNNING', 'userId': 'bh0085_gmail_com'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsname = dataset[\"dataset\"]\n",
    "\n",
    "#READ TRANSCRIPT ALIGNMENTS\n",
    "samfile = pysam.AlignmentFile(\"/data/dd-analysis/datasets/{}/tophat/accepted_hits.bam\".format(dsname), \"rb\")\n",
    "all_alignments = [a for a in  samfile]\n",
    "names =[e.reference_name for e in all_alignments]\n",
    "query_names = [e.query_name for e in all_alignments]\n",
    "\n",
    "#LOAD TRANSCRIPTOME FASTA FILE\n",
    "#this is the file that the reads above were aligned to and contains add'l annotations\n",
    "with open(\"/data/transcriptomes/Homo_sapiens.GRCh38.cdna.all.fa\") as f:\n",
    "    farecords = SeqIO.parse(f, \"fasta\")\n",
    "    recs = [r for r in farecords]\n",
    "for r in recs:\n",
    "    r.id = r.id[:r.id.index(\".\")]\n",
    "\n",
    "\n",
    "\n",
    "gsre = re.compile(\"gene_symbol:(\\S+)\")\n",
    "dre = re.compile(\"description:(.*)\")\n",
    "chromre = re.compile(\"chromosome:(\\S+)\")\n",
    "genere = re.compile(\"gene:(\\S+)\")\n",
    "\n",
    "transcript_gene_symbols = dict([(r.id, gsre.search(r.description).groups()[0]) for r in recs if \"gene_symbol:\" in r.description])\n",
    "transcript_descriptions = dict([(r.id, dre.search(r.description).groups()[0]) for r in recs if \"description:\" in r.description])\n",
    "transcript_chromosome = dict([(r.id, chromre.search(r.description).groups()[0]) for r in recs if \"chromosome:\" in r.description])\n",
    "transcript_geneid_withversion = dict([(r.id, genere.search(r.description).groups()[0]) for r in recs if \"description:\" in r.description])\n",
    "transcript_geneid = dict([(k,v[:v.index(\".\")]) for k, v in transcript_geneid_withversion.items()])\n",
    "entrez_by_gene = entrez.drop_duplicates(\"gene_stable_id\").set_index(entrez.drop_duplicates(\"gene_stable_id\").gene_stable_id)\n",
    "mapped_genes = set(g for g in transcript_geneid.values() if entrez_by_gene.index.contains(g))\n",
    "transcript_xref = dict([(k ,entrez_by_gene.loc[g].xref if g in mapped_genes else None) for k,g in transcript_geneid.items() ])\n",
    "\n",
    "\n",
    "#many-to-one mapping between UMI_IDS and transcripts\n",
    "umi2tx = pd.DataFrame.from_dict([{\"umi_id\":qn,\"dataset\":qn.split(\"_\")[0],\"umi\":qn.split(\"_\")[1],\"transcript\":names[i][:names[i].index(\".\")]} \n",
    "                                for i,qn in enumerate(query_names)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/go/go-basic.obo: fmt(1.2) rel(2019-03-19) 47,381 GO Terms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#mappping from transcript gene symbols (recorded in the ensembl cdna file to \n",
    "#refseq genes\n",
    "\n",
    "refseq_symbol_names_jointable = pd.concat([refseq_genes.name2,refseq_genes.name],axis = 1)\n",
    "refseq_symbols_idx = pd.Index(refseq_genes.name2.drop_duplicates().str.upper())\n",
    "refseq_symbol_ids = pd.Series(refseq_genes.name2.drop_duplicates().index, index=refseq_symbols_idx)\n",
    "\n",
    "tx_symbols = pd.Series(transcript_gene_symbols)\n",
    "refseq_matches = tx_symbols.apply(lambda x: refseq_symbol_ids[x] if x in refseq_symbols_idx else None).dropna()\n",
    "#roughly 85% of transcripts can be matched refseq IDs\n",
    "transcript_refseqs = refseq_matches.apply(lambda x: refseq_genes.name.loc[x])\n",
    "\n",
    "TX_INFO = pd.concat([pd.Series(transcript_descriptions).rename(\"desc\"),\n",
    "                 pd.Series(transcript_gene_symbols).rename(\"symbol\"),\n",
    "                pd.Series(transcript_geneid).rename(\"ensembl_gene\"),\n",
    "                 pd.Series(transcript_xref).rename(\"ncbi_gene\")\n",
    "                ],axis = 1, sort=True)\n",
    "\n",
    "all_umis = umi2tx.umi_id.unique()\n",
    "\n",
    "\n",
    "#GOTTA REMEMBER TO FILTER OUT ALL SHITTY UMIS!\n",
    "nosegfeat_fn = f\"/data/tmp/watch_sequences/{dsname}/xumi_feat_{dsname}\"\n",
    "nosegfeat_df = pd.read_csv(nosegfeat_fn,names=[\"umi\",\"check\",\"blank1\",\"blank2\",\"sequence\"])\n",
    "nosegfeat_df.iloc[:,1].unique()\n",
    "good_umis_idx = nosegfeat_df.loc[nosegfeat_df.iloc[:,1]==0].index\n",
    "\n",
    "segfn = f\"/data/tmp/watch_sequences/{dsname}/xumi_segment_base_{dsname}\"\n",
    "segdf = pd.read_csv(segfn,names=[\"umi\",\"seg\",\"1\",\"2\",\"3\"]).loc[good_umis_idx]\n",
    "\n",
    "go_obo_url = 'http://purl.obolibrary.org/obo/go/go-basic.obo'\n",
    "data_folder = '/data/go'\n",
    "\n",
    "# Check if we have the ./data directory already\n",
    "if(not os.path.isfile(data_folder)):\n",
    "    # Emulate mkdir -p (no error if folder exists)\n",
    "    try:\n",
    "        os.mkdir(data_folder)\n",
    "    except OSError as e:\n",
    "        if(e.errno != 17):\n",
    "            raise e\n",
    "else:\n",
    "    raise Exception('Data path (' + data_folder + ') exists as a file. '\n",
    "                   'Please rename, remove or change the desired location of the data path.')\n",
    "\n",
    "# Check if the file exists already\n",
    "if(not os.path.isfile(data_folder+'/go-basic.obo')):\n",
    "    go_obo = wget.download(go_obo_url, data_folder+'/go-basic.obo')\n",
    "else:\n",
    "    go_obo = data_folder+'/go-basic.obo'\n",
    "\n",
    "# Import the OBO parser from GOATools\n",
    "go = obo_parser.GODag(go_obo)\n",
    "\n",
    "\n",
    "a0 = ontologies.sort_values(\"DB_Object_Symbol\")\n",
    "\n",
    "#for each cell in the selected segmentation, list all transcripts (with counts)\n",
    "#that appear\n",
    "\n",
    "\n",
    "\n",
    "umi2txall = umi2tx.join( TX_INFO,on = \"transcript\")\n",
    "ontologies_by_symbol = ontologies.set_index(ontologies.DB_Object_Symbol)\n",
    "ontologies_by_symbol[\"GO_NAME\"] = ontologies_by_symbol.GO_ID.apply(lambda x: go[x].name).rename(\"GO_NAME\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
