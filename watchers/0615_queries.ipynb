{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset_models\n",
    "import imp\n",
    "imp.reload(dataset_models)\n",
    "\n",
    "import pandas as pd\n",
    "from dataset_models import Umi, session, db, Dataset, GeneGoTerm, UmiGeneId, GoTerm, NcbiGene, Segment\n",
    "\n",
    "rsq = pd.read_sql_query\n",
    "sq = session.query\n",
    "\n",
    "from sqlalchemy import desc, asc, func, distinct\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy import stats\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dsname= \"29045011805220233\"\n",
    "getDatasetId =  lambda dsname: int(dsname[:8])\n",
    "\n",
    "nm = dsname\n",
    "out_folder = os.path.join(f\"/data/dd-analysis/datasets/{nm}/segmentations/\")\n",
    "if not os.path.isdir(out_folder):\n",
    "        os.makedirs(out_folder)\n",
    "\n",
    "def winning_pixels_file(dsname):\n",
    "    out_folder = os.path.join(f\"/data/dd-analysis/datasets/{dsname}/segmentations/\")\n",
    "    fn = os.path.join(out_folder,\"winning_pixels.csv\")\n",
    "    \n",
    "def passing_pixels_file(dsname):\n",
    "    out_folder = os.path.join(f\"/data/dd-analysis/datasets/{dsname}/segmentations/\")\n",
    "    fn = os.path.join(out_folder,\"passing_pixels.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n"
     ]
    }
   ],
   "source": [
    "getDatasetId =  lambda dsname: int(dsname[:8])\n",
    "umis= rsq(sq(Umi).filter(Umi.dsid==getDatasetId(\"29045011\")).statement,db).rename({\"id\":\"umi_id\"},axis=\"columns\").set_index(\"umi_id\")\n",
    "# initialize segment information\n",
    "segment_umis = rsq(sq(Umi.dsid,Umi.id.label(\"umi_id\"),Umi.x,Umi.y,Segment.id.label(\"seg_id\")).filter(Umi.dsid==29045011).join(Segment).statement,db)\n",
    "segs = segment_umis.join(segment_umis.seg_id.value_counts().rename(\"seg_umi_count\"), on = \"seg_id\").loc[lambda x: x.seg_umi_count>1]\n",
    "segs_by_id = segs.set_index(\"seg_id\")\n",
    "\n",
    "#compute normalized distances to cell centers using eigenvectors of the covariance matrix\n",
    "esys = segs_by_id.groupby(\"seg_id\").apply(lambda g: np.linalg.eig(np.cov(*g[[\"x\",\"y\"]].values.T)))\n",
    "emeans = segs_by_id[[\"x\",\"y\"]].groupby(\"seg_id\").mean()\n",
    "proj_dist = segs_by_id.reset_index().set_index(\"umi_id\").apply(\n",
    "    lambda u:(lambda e: (np.dot(u[[\"x\",\"y\"]] - emeans.loc[u.seg_id] ,e[1][:,0])/(e[0][0]**.5))**2 + \\\n",
    "                        (np.dot(u[[\"x\",\"y\"]] - emeans.loc[u.seg_id] ,e[1][:,1])/(e[0][1]**.5))**2)(esys.loc[u.seg_id]),axis=1)\\\n",
    "    .rename(\"transformed_dist\")\n",
    "\n",
    "\n",
    "segs_with_dists = segs_by_id.join(proj_dist.reset_index().set_index(\"umi_id\"),on=\"umi_id\")\n",
    "segs_with_dists = segs_with_dists.join(umis[[\"total_reads\"]],on=\"umi_id\")\n",
    "\n",
    "combined_series = pd.Series()\n",
    "\n",
    "i = 0\n",
    "for k, g in segs_with_dists.groupby(level=0):\n",
    "    gsubs = g.loc[g.total_reads>0]\n",
    "    xmin= gsubs.x.mean()- (np.max([gsubs.x.std(),.5]))\n",
    "    xmax= gsubs.x.mean()+ (np.max([gsubs.x.std(),.5]))\n",
    "    ymin= gsubs.y.mean()- (np.max([gsubs.y.std(),.5]))\n",
    "    ymax= gsubs.y.mean()+ (np.max([gsubs.y.std(),.5]))\n",
    "\n",
    "    #X, Y = np.mgrid[xmin:xmax:500j, ymin:ymax:500j]\n",
    "\n",
    "    pts = 2\n",
    "    res = 10**(-1*pts)\n",
    "    #print(res)\n",
    "    X, Y = np.round(np.mgrid[np.round(xmin,pts):np.round(xmax,pts):res, np.round(ymin,pts):np.round(ymax,pts):res],pts)\n",
    "    positions = np.vstack([X.ravel(), Y.ravel()])\n",
    "\n",
    "    values = np.vstack([gsubs.x,gsubs.y])\n",
    "    kernel = stats.gaussian_kde(values,weights=np.log(gsubs.total_reads.astype(float).values))#, bw_method=1,)\n",
    "    Z = np.reshape(kernel.evaluate(positions).T, X.shape)\n",
    "\n",
    "    df = pd.DataFrame(Z)#/ np.sum(Z)\n",
    "    df.columns =pd.Series(Y[0,:]).rename(\"y\")\n",
    "    df.index =pd.Series(X[:,0]).rename(\"x\")\n",
    "\n",
    "    series = pd.DataFrame(df.stack()).assign(g=k).set_index(\"g\",append=True).iloc[:,0]\n",
    "    combined_series = pd.concat([series,combined_series])\n",
    "    \n",
    "    i+=1\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "\n",
    "    \n",
    "combined_series=combined_series.rename(\"kde_vals\")\n",
    "val_sorted  = combined_series.sort_values(0,ascending=False).sort_index(level=[0,1], sort_remaining=False)\n",
    "\n",
    "#threshold kde distributions to create \"passing\" pixels considered to be hits for each cell segment\n",
    "passing_pixels = val_sorted.groupby(\"g\").apply(lambda x: x.loc[x> 1]).reset_index(level=0,drop=True)\n",
    "\n",
    "#argmax thresholded kde distributions to create bitmasks indicating which cell will have precendence in each pixel\n",
    "best_seg = val_sorted.reset_index(level = \"g\").loc[lambda x: ~x.index.duplicated()].g\n",
    "best_val = val_sorted.reset_index(level = \"g\").loc[lambda x: ~x.index.duplicated()].kde_vals\n",
    "winning_pixels = best_seg.loc[best_val > 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sns.scatterplot(x= \"x\", y = \"y\",data= segs_with_dists.loc[lambda x: x.transformed_dist > .5], s=2,alpha=.2,edgecolor=None)\n",
    "rscl= 1\n",
    "sns.scatterplot(x= \"x\", y = \"y\",data= segs_with_dists.loc[lambda x: x.transformed_dist < .5],alpha=.2,edgecolor=None, s=10,)\n",
    "f = plt.gcf()\n",
    "f.set_size_inches(5,5)\n",
    "plt.gca().set_xlim([0,6])\n",
    "plt.gca().set_ylim([0,6])\n",
    "ax = plt.gca()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## f = plt.gcf()\n",
    "f.set_size_inches(12,12)\n",
    "sns.heatmap((winning_pixels.unstack(\"y\").T.sort_index().T- best_seg.min().min()).fillna(0))\n",
    "\n",
    "ax = plt.gca()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "winning_pixels.rename(\"segment\").to_frame().to_csv(winning_pixels_file(dsname))\n",
    "passing_pixels.rename(\"kde_val\").to_frame().to_csv(passing_pixels_file(dsname))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'NoneType'>",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "winning_pixels2 = pd.read_csv(winning_pixels_file(dsname),index_col=[\"x\",\"y\"])\n",
    "passing_pixels2 = pd.read_csv(passing_pixels_file(dsname),index_col=[\"x\",\"y\",\"g\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(winning_pixels_file(dsname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "def confidence_ellipse(x, y, ax=None, n_std=3.0, facecolor='none', **kwargs):\n",
    "    \"\"\"\n",
    "    Create a plot of the covariance confidence ellipse of `x` and `y`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : array_like, shape (n, )\n",
    "        Input data.\n",
    "\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The axes object to draw the ellipse into.\n",
    "\n",
    "    n_std : float\n",
    "        The number of standard deviations to determine the ellipse's radiuses.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.patches.Ellipse\n",
    "\n",
    "    Other parameters\n",
    "    ----------------\n",
    "    kwargs : `~matplotlib.patches.Patch` properties\n",
    "    \"\"\"\n",
    "    if x.size != y.size:\n",
    "        raise ValueError(\"x and y must be the same size\")\n",
    "\n",
    "    cov = np.cov(x, y)\n",
    "    pearson = cov[0, 1]/np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "    # Using a special case to obtain the eigenvalues of this\n",
    "    # two-dimensionl dataset.\n",
    "    ell_radius_x = np.sqrt(1 + pearson)\n",
    "    ell_radius_y = np.sqrt(1 - pearson)\n",
    "    ellipse = Ellipse((0, 0),\n",
    "        width=ell_radius_x * 2,\n",
    "        height=ell_radius_y * 2,\n",
    "        facecolor=facecolor,\n",
    "        **kwargs)\n",
    "\n",
    "    # Calculating the stdandard deviation of x from\n",
    "    # the squareroot of the variance and multiplying\n",
    "    # with the given number of standard deviations.\n",
    "    scale_x = np.sqrt(cov[0, 0]) * n_std\n",
    "    mean_x = np.mean(x)\n",
    "\n",
    "    # calculating the stdandard deviation of y ...\n",
    "    scale_y = np.sqrt(cov[1, 1]) * n_std\n",
    "    mean_y = np.mean(y)\n",
    "\n",
    "    transf = transforms.Affine2D() \\\n",
    "        .rotate_deg(45) \\\n",
    "        .scale(scale_x, scale_y) \\\n",
    "        .translate(mean_x, mean_y)\n",
    "    \n",
    "    if ax is None:\n",
    "        ellipse.set_transform(transf) \n",
    "    else:\n",
    "        ellipse.set_transform(transf+ ax.transData)\n",
    "            \n",
    "        \n",
    "    return ellipse\n",
    "    #return ax.add_patch(ellipse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
